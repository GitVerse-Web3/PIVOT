{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class BigModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BigModel, self).__init__()\n",
    "        self.fc = nn.Linear(500, 500)  # 500 * 500 = 250,000 parameters\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "生成一个1MB的模型，需要大约250,000个参数，因为1MB = 1024 * 1024字节，所以大约250,000个参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建模型实例\n",
    "model = BigModel()\n",
    "\n",
    "# 保存模型\n",
    "torch.save(model.state_dict(), 'big_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 0.9570655822753906 MB\n"
     ]
    }
   ],
   "source": [
    "# 检查模型大小\n",
    "import os\n",
    "print(f'Model size: {os.path.getsize(\"big_model.pth\") / 1024 / 1024} MB')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在这个例子中，我们首先保存模型的参数（model.state_dict()），然后训练模型并保存新的参数。我们计算参数的更新（新的参数减去旧的参数），并保存这些更新。当我们需要加载模型时，我们加载旧的参数和更新，然后应用这些更新（旧的参数加上更新）。\n",
    "这个例子只是一个基本的示例，实际情况可能会更复杂 🐶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# 创建优化器\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "# 创建损失函数\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# 创建一个简单的数据集\n",
    "inputs = torch.randn(10, 500)\n",
    "targets = torch.randn(10, 500)\n",
    "\n",
    "# 保存旧的状态字典\n",
    "old_state_dict = {name: param.data.clone() for name, param in model.state_dict().items()}\n",
    "\n",
    "# 训练模型\n",
    "model.train()\n",
    "optimizer.zero_grad()\n",
    "outputs = model(inputs)\n",
    "loss = criterion(outputs, targets)\n",
    "loss.backward()\n",
    "optimizer.step()\n",
    "\n",
    "# 保存新的状态字典\n",
    "new_state_dict = {name: param.data for name, param in model.state_dict().items()}\n",
    "\n",
    "# 计算参数的更新\n",
    "updates = {name: new_state_dict[name] - old_state_dict[name] for name in new_state_dict}\n",
    "\n",
    "# 保存模型和参数更新\n",
    "torch.save(new_state_dict, 'new_model.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "得到参数更新的update模型和最后结果的模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fc.weight torch.Size([500, 500])\n",
      "fc.bias torch.Size([1, 500])\n"
     ]
    }
   ],
   "source": [
    "# 将updates中的一维矩阵转换为二维\n",
    "for key in updates:\n",
    "    if updates[key].ndim == 1:\n",
    "        updates[key] = updates[key].view(1, -1) \n",
    "\n",
    "for key in updates:\n",
    "    print(key, updates[key].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将一维的tensor的转换为2维, 方便之后使用奇异值分解（SVD）求的低秩近似。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def low_rank_approximation(matrix, k):\n",
    "    \"\"\"返回矩阵的低秩近似，k为奇异值个数\"\"\"\n",
    "    U, s, Vh = np.linalg.svd(matrix, full_matrices=False)\n",
    "    U_k = U[:, :k]\n",
    "    s_k = s[:k]\n",
    "    Vh_k = Vh[:k, :]\n",
    "    return U_k @ np.diag(s_k) @ Vh_k\n",
    "\n",
    "# 对每个参数应用低秩近似\n",
    "k = 10  # 你可以根据需要设置k的值\n",
    "updates_approx = {}\n",
    "for name, update in updates.items():\n",
    "    # 检查更新是否为二维数组\n",
    "    if len(update.shape) == 2:\n",
    "        # 首先将Tensor转换为numpy数组，进行SVD，然后再转回Tensor\n",
    "        update_numpy = update.cpu().numpy()\n",
    "        update_approx_numpy = low_rank_approximation(update_numpy, k)\n",
    "        updates_approx[name] = torch.from_numpy(update_approx_numpy).to(update.device)\n",
    "    else:\n",
    "        # 对于一维数组，我们只是简单地复制更新\n",
    "        updates_approx[name] = update.clone()\n",
    "\n",
    "torch.save(updates_approx, 'updates.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用奇异值分解（SVD）来获取一个矩阵的低秩近似。\n",
    "🐶 但不起效果。\n",
    "应该将将一些全连接层（或卷积层）替换为低秩版本。这涉及模型压缩或模型剪枝，难度颇大，黑客松上暂时不考虑。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 0.9568710327148438 MB\n"
     ]
    }
   ],
   "source": [
    "# 检查模型大小\n",
    "import os\n",
    "print(f'Model size: {os.path.getsize(\"updates.pth\") / 1024 / 1024} MB')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
